# ğŸ§  Smart Research Assistant (Offline + Free with Ollama)

A GenAI-powered assistant that reads research documents (PDF/TXT), summarizes them, answers custom questions, and generates logic-based challenges â€” all **offline** using **open-source models** like `phi3` via Ollama.

## ğŸš€ Features

- ğŸ“„ Upload PDF or TXT documents
- ğŸ§¾ Automatic summary (within 100 words)
- â“ Ask anything (context-aware question answering)
- ğŸ§  Challenge Me mode (logic-based quiz generation and evaluation)
- ğŸ”Œ 100% offline using Ollama (`phi3` or other small models)
- ğŸ” Justifies each answer with document references

---

## ğŸ—ï¸ Project Architecture

smart-assistant/
â”œâ”€â”€ backend/ â† FastAPI server
â”‚ â”œâ”€â”€ app.py â† Main API (summary, ask, challenge, evaluate)
â”‚ â””â”€â”€ utils/
â”‚ â”œâ”€â”€ parser.py â† Handles PDF and TXT parsing
â”‚ â”œâ”€â”€ summarizer.py â† Summarizes content using Ollama
â”‚ â”œâ”€â”€ asker.py â† Q&A logic using local LLM + embeddings
â”‚ 
â”œâ”€â”€ frontend/ â† Streamlit UI
â”‚ â””â”€â”€ app.py â† User-facing interface
â”œâ”€â”€ README.md


## ğŸ› ï¸ Setup Instructions

###  1. Install Required Tools

- Python 3.10+: [Download](https://www.python.org/downloads/)
- VS Code (optional): [Download](https://code.visualstudio.com/)
- Ollama: [https://ollama.com](https://ollama.com)

###  2. Pull Lightweight LLM

Use `phi3` (fast and memory-efficient):
bash
ollama run phi3

âœ… 4. Install Python Dependencies
pip install requests sentence-transformers pdfplumber fastapi pydantic uvicorn streamlit

âœ… 5. Run the Backend (FastAPI)
cd backend
python -m uvicorn app:app --reload --port 7860
You should see:
Uvicorn running on http://127.0.0.1:7860

âœ… 6. Run the Frontend (Streamlit)
In a new terminal:
cd frontend
streamlit run app.py
App opens at:
http://localhost:8501



